{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "## Problem Type\n",
    "**Convolutional Neural Networks (CNNs)** are primarily used for:\n",
    "- **Image Classification** problems\n",
    "- **Supervised** learning\n",
    "- **Object Detection**, **Image Segmentation**, **Video Analysis**\n",
    "\n",
    "### How CNNs Work\n",
    "- **Convolutional layers:**\n",
    "  - Apply convolutional filters (kernels) to input images to detect spatial patterns like edges, textures, and more complex features.\n",
    "  - Multiple filters learn different features at each layer, capturing increasingly abstract representations.\n",
    "- **Pooling layers:**\n",
    "  - Reduce the spatial dimensions (width and height) of the feature maps, keeping the most essential information and reducing computational complexity.\n",
    "  - Common pooling methods include Max Pooling (selecting the maximum value) and Average Pooling (taking the average value).\n",
    "- **Activation functions:**\n",
    "  - Introduce non-linearity into the model to allow it to learn complex patterns.\n",
    "  - Common functions include ReLU (Rectified Linear Unit), which replaces negative values with zero, and others like sigmoid or tanh.\n",
    "- **Fully connected layers:**\n",
    "  - Flatten the feature maps and connect them to fully connected layers for the final classification.\n",
    "  - The last layer usually applies a softmax activation for multi-class classification or sigmoid for binary classification.\n",
    "- **Backpropagation:**\n",
    "  - Uses gradients to update the weights in the network based on the error between the predicted and actual labels.\n",
    "  - The learning process involves minimizing a loss function through optimization techniques like stochastic gradient descent (SGD) or Adam.\n",
    "\n",
    "### Key Tuning Metrics\n",
    "- **`filter_size` (Kernel Size):**\n",
    "  - **Description:** Size of the convolutional filter applied to the input data.\n",
    "  - **Impact:** Larger filters capture broader features but may lose fine details; common sizes include 3x3, 5x5.\n",
    "  - **Default:** Typically `3x3` or `5x5`.\n",
    "- **`stride`:**\n",
    "  - **Description:** Step size by which the filter moves across the input.\n",
    "  - **Impact:** Larger strides reduce the output size, leading to faster computations but may skip over important features.\n",
    "  - **Default:** `1`.\n",
    "- **`padding`:**\n",
    "  - **Description:** Padding added to the input to control the spatial size of the output.\n",
    "  - **Impact:** `same` padding keeps output size the same as input, while `valid` padding reduces it.\n",
    "  - **Default:** `valid` (no padding).\n",
    "- **`number of filters`:**\n",
    "  - **Description:** Number of filters (or feature maps) in a convolutional layer.\n",
    "  - **Impact:** More filters capture more features, increasing model capacity but also computational cost.\n",
    "  - **Default:** Varies by layer; usually starts with `32` or `64` and increases in deeper layers.\n",
    "- **`learning_rate`:**\n",
    "  - **Description:** Step size for updating weights during training.\n",
    "  - **Impact:** Higher values speed up training but may cause instability; lower values provide more stable convergence but slow down training.\n",
    "  - **Default:** `0.001` (varies with optimizer).\n",
    "- **`dropout_rate`:**\n",
    "  - **Description:** Fraction of units to drop during training to prevent overfitting.\n",
    "  - **Impact:** Helps in regularization; typical values range from `0.2` to `0.5`.\n",
    "  - **Default:** Varies, typically `0.5` in fully connected layers.\n",
    "\n",
    "### Pros vs Cons\n",
    "\n",
    "| Pros                                                  | Cons                                                   |\n",
    "|-------------------------------------------------------|--------------------------------------------------------|\n",
    "| Highly effective for image and spatial data           | Requires large amounts of labeled data for training    |\n",
    "| Automatically learns hierarchical feature representations | Computationally expensive, especially with deep networks |\n",
    "| Can handle large input dimensions (e.g., images)      | Prone to overfitting without sufficient regularization  |\n",
    "| Transfer learning allows reuse of pre-trained models  | Complex architecture requires careful tuning of hyperparameters |\n",
    "| Well-supported by deep learning libraries like TensorFlow and PyTorch | Difficult to interpret learned features and decisions  |\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Accuracy (Classification):**\n",
    "  - **Description:** Ratio of correct predictions to total predictions.\n",
    "  - **Good Value:** Higher is better; values above 0.85 indicate strong model performance.\n",
    "  - **Bad Value:** Below 0.5 suggests poor model performance.\n",
    "- **Precision (Classification):**\n",
    "  - **Description:** Proportion of true positives among all positive predictions.\n",
    "  - **Good Value:** Higher values indicate fewer false positives, especially important in imbalanced datasets.\n",
    "  - **Bad Value:** Low values suggest many false positives.\n",
    "- **Recall (Classification):**\n",
    "  - **Description:** Proportion of actual positives correctly identified.\n",
    "  - **Good Value:** Higher values indicate fewer false negatives, important in recall-sensitive applications.\n",
    "  - **Bad Value:** Low values suggest many false negatives.\n",
    "- **F1 Score (Classification):**\n",
    "  - **Description:** Harmonic mean of Precision and Recall.\n",
    "  - **Good Value:** Higher values indicate a good balance between Precision and Recall.\n",
    "  - **Bad Value:** Low values suggest a poor balance between Precision and Recall.\n",
    "- **AUC-ROC (Classification):**\n",
    "  - **Description:** Measures the ability of the model to distinguish between classes across all thresholds.\n",
    "  - **Good Value:** Values closer to 1 indicate strong separability between classes.\n",
    "  - **Bad Value:** Values near 0.5 suggest random guessing.\n",
    "- **Cross-Entropy Loss (Log Loss):**\n",
    "  - **Description:** Measures the performance of a classification model where the output is a probability value between 0 and 1.\n",
    "  - **Good Value:** Lower values indicate better model calibration and performance.\n",
    "  - **Bad Value:** Higher values suggest poor probabilistic predictions.\n",
    "- **Top-K Accuracy (for multi-class classification):**\n",
    "  - **Description:** Measures if the correct label is among the top K predicted probabilities.\n",
    "  - **Good Value:** Higher values, especially in problems with many classes.\n",
    "  - **Bad Value:** Lower values suggest the model struggles to capture multiple class distinctions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Suppresses INFO and WARNING messages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.title(f\"Label: {train_labels[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# add colour channel as expected by conv2D\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalise images between 0 and 1\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# one hot encoding\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(28, 28, 1))) \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, batch_size=128, epochs=10, verbose=1, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training the model\n",
    "predictions = model.predict(test_images)\n",
    "predictions = np.argmax(predictions, axis=1)  # Convert predictions to labels\n",
    "true_labels = np.argmax(test_labels, axis=1)  # Convert one-hot encoded y_test to labels\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Use Seaborn to plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-ktax2Mo_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
