{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "## Problem Type\n",
    "**K-Means Clustering** is primarily used for:\n",
    "- **Clustering** problems\n",
    "- **Unsupervised** learning\n",
    "\n",
    "### How K-Means Clustering Works\n",
    "- **Partitioning method:**\n",
    "  - Divides a dataset into `k` distinct, non-overlapping clusters.\n",
    "- **Centroid-based clustering:**\n",
    "  - Each cluster is represented by its centroid, which is the mean of all points in that cluster.\n",
    "- **Iterative refinement:**\n",
    "  - Randomly initializes `k` centroids, then assigns each point to the nearest centroid.\n",
    "  - Centroids are recalculated as the mean of the points assigned to them.\n",
    "  - The process repeats until centroids no longer change significantly (convergence).\n",
    "- **Objective function:**\n",
    "  - Minimizes the sum of squared distances (inertia) between each point and its corresponding centroid.\n",
    "- **Cluster assignment:**\n",
    "  - Points are assigned to the cluster with the nearest centroid, often using Euclidean distance.\n",
    "\n",
    "### Key Tuning Metrics\n",
    "- **`n_clusters`:**\n",
    "  - **Description:** Number of clusters (`k`) to form.\n",
    "  - **Impact:** Directly influences the clustering result; higher values can capture more granularity but may overfit the data.\n",
    "  - **Default:** No default; must be specified.\n",
    "- **`init`:**\n",
    "  - **Description:** Method for initializing centroids (`k-means++`, `random`).\n",
    "  - **Impact:** `k-means++` reduces the chances of poor clustering results by spreading out initial centroids.\n",
    "  - **Default:** `k-means++`.\n",
    "- **`max_iter`:**\n",
    "  - **Description:** Maximum number of iterations to run the algorithm.\n",
    "  - **Impact:** More iterations allow better convergence but increase computational time.\n",
    "  - **Default:** `300`.\n",
    "- **`n_init`:**\n",
    "  - **Description:** Number of times the algorithm will be run with different centroid seeds.\n",
    "  - **Impact:** Multiple initializations can avoid local minima, improving the final clustering solution.\n",
    "  - **Default:** `10`.\n",
    "- **`tol`:**\n",
    "  - **Description:** Relative tolerance with respect to the change in the centroid positions to declare convergence.\n",
    "  - **Impact:** Lower values may lead to more precise clusters but require more iterations.\n",
    "  - **Default:** `1e-4`.\n",
    "\n",
    "### Pros vs Cons\n",
    "\n",
    "| Pros                                                  | Cons                                                   |\n",
    "|-------------------------------------------------------|--------------------------------------------------------|\n",
    "| Simple and easy to implement                           | Requires the number of clusters (`k`) to be predefined  |\n",
    "| Scales well to large datasets                          | Sensitive to initial centroid positions, which can lead to local minima |\n",
    "| Efficient with linear time complexity relative to the number of data points | Assumes spherical clusters, which may not fit complex data distributions |\n",
    "| Works well with compact, well-separated clusters       | Struggles with clusters of varying sizes and densities  |\n",
    "| Can be used as a preprocessing step for other algorithms | Not deterministic; results may vary with different initializations |\n",
    "\n",
    "### Evaluation Metrics\n",
    "- **Inertia (Within-cluster Sum of Squares):**\n",
    "  - **Description:** Measures the sum of squared distances between each point and its corresponding centroid.\n",
    "  - **Good Value:** Lower values indicate tighter clusters; relative decrease in inertia can help determine the optimal `k`.\n",
    "  - **Bad Value:** High values suggest loose clustering; no significant drop may indicate poor clustering.\n",
    "- **Silhouette Score:**\n",
    "  - **Description:** Measures how similar points are to their own cluster compared to other clusters.\n",
    "  - **Good Value:** Values close to 1 indicate well-separated clusters.\n",
    "  - **Bad Value:** Values near 0 suggest overlapping clusters, while negative values indicate points might be assigned to the wrong cluster.\n",
    "- **Elbow Method:**\n",
    "  - **Description:** Plots the inertia for different values of `k` to find the \"elbow point,\" where adding more clusters does not significantly improve the model.\n",
    "  - **Good Value:** The elbow point suggests the optimal number of clusters.\n",
    "  - **Bad Value:** A smooth curve with no clear elbow suggests ambiguity in the optimal `k`.\n",
    "- **Davies-Bouldin Index:**\n",
    "  - **Description:** Measures the average similarity ratio of each cluster with its most similar cluster (lower is better).\n",
    "  - **Good Value:** Values close to 0 indicate well-separated clusters.\n",
    "  - **Bad Value:** Higher values suggest that clusters are not distinct.\n",
    "- **Dunn Index:**\n",
    "  - **Description:** Ratio of the minimum inter-cluster distance to the maximum intra-cluster distance (higher is better).\n",
    "  - **Good Value:** Higher values indicate well-separated and compact clusters.\n",
    "  - **Bad Value:** Lower values suggest poor cluster separation and cohesion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate within-cluster sum of squares (WCSS) for different K values\n",
    "wcss = []\n",
    "for k in range(1, 11):\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X_scaled)\n",
    "    wcss.append(model.inertia_)  # Inertia is the WCSS value\n",
    "\n",
    "# Plot the Elbow curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering\n",
    "model = KMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    max_iter=300,\n",
    "    n_init=10,\n",
    "    tol=0.0001,\n",
    "    random_state=42,\n",
    ")\n",
    "model.fit(X_scaled)\n",
    "\n",
    "# Get cluster assignments and centroids\n",
    "cluster_labels = model.labels_\n",
    "centroids = model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters (using PCA for 2D visualization)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', edgecolor='k')\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=100, label='Centroids')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('K-means Clustering of Iris Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-ktax2Mo_-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
